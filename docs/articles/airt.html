<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Introduction to airt • airt</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/all.min.css" integrity="sha256-nAmazAk6vS34Xqo0BSrTb+abbtFlgsFK7NKSi6o7Y78=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/v4-shims.min.css" integrity="sha256-6qHlizsOWFskGlwVOKuns+D1nB6ssZrHQrNj1wGplHc=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/headroom.min.js" integrity="sha256-DJFC1kqIhelURkuza0AvYal5RxMtpzLjFhsnVIeuk+U=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Introduction to airt">
<meta property="og:description" content="">
<meta property="og:image" content="/logo.png">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">airt</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.2.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/airt.html">Get started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="airt_files/header-attrs-2.1/header-attrs.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Introduction to airt</h1>
            
      
      
      <div class="hidden name"><code>airt.Rmd</code></div>

    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1"></a><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(airt)</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(ggplot2)</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(tidyr)</span></code></pre></div>
<p>The goal of <em>airt</em> is to evaluate performance of algorithms using Item Response Theory (IRT). You can use <em>airt</em> to evaluate the performance of a group of algorithms on a collection of test instances. The IRT model is fitted using the R package <strong>mirt</strong> .</p>
<div id="classification-algorithms---continuous-irt-model" class="section level2">
<h2 class="hasAnchor">
<a href="#classification-algorithms---continuous-irt-model" class="anchor"></a>Classification Algorithms - Continuous IRT model</h2>
<p>This example is on classification algorithms. The data <em>classification</em> has performance data from 10 classification algorithms on 235 datasets. This data is discussed in <span class="citation">(Muñoz et al. 2018)</span> and can be found at the test instance library MATILDA <span class="citation">(Smith-Miles 2019)</span>.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1"></a><span class="kw"><a href="https://rdrr.io/r/utils/data.html">data</a></span>(<span class="st">"classification_cts"</span>)</span>
<span id="cb2-2"><a href="#cb2-2"></a>df2 &lt;-<span class="st"> </span>classification_cts</span>
<span id="cb2-3"><a href="#cb2-3"></a>max_item  &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span>(df2)</span>
<span id="cb2-4"><a href="#cb2-4"></a>min_item &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb2-5"><a href="#cb2-5"></a>max.item &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/rep.html">rep</a></span>(max_item, <span class="kw"><a href="https://rdrr.io/r/base/dim.html">dim</a></span>(df2)[<span class="dv">2</span>])</span>
<span id="cb2-6"><a href="#cb2-6"></a>min.item &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/rep.html">rep</a></span>(min_item, <span class="kw"><a href="https://rdrr.io/r/base/dim.html">dim</a></span>(df2)[<span class="dv">2</span>])</span>
<span id="cb2-7"><a href="#cb2-7"></a>df2 &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span>(df2)</span>
<span id="cb2-8"><a href="#cb2-8"></a>modout &lt;-<span class="st"> </span><span class="kw"><a href="../reference/cirtmodel.html">cirtmodel</a></span>(df2, max.item, min.item)</span>
<span id="cb2-9"><a href="#cb2-9"></a>paras &lt;-<span class="st"> </span>modout<span class="op">$</span>model<span class="op">$</span>param</span>
<span id="cb2-10"><a href="#cb2-10"></a></span>
<span id="cb2-11"><a href="#cb2-11"></a>gdf &lt;-<span class="st"> </span><span class="kw"><a href="../reference/prepare_for_plots_crm.html">prepare_for_plots_crm</a></span>(modout<span class="op">$</span>model) </span>
<span id="cb2-12"><a href="#cb2-12"></a><span class="kw">ggplot</span>(gdf, <span class="kw">aes</span>(theta, z)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_raster</span>(<span class="kw">aes</span>(<span class="dt">fill=</span>pdf))  <span class="op">+</span><span class="st"> </span><span class="kw">xlab</span>(<span class="st">"theta"</span>) <span class="op">+</span><span class="st"> </span><span class="kw">facet_wrap</span>(<span class="op">~</span>Algorithm, <span class="dt">nrow=</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">coord_fixed</span>(<span class="dt">ratio=</span><span class="dv">1</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()  <span class="op">+</span><span class="st">  </span><span class="kw">scale_fill_viridis_c</span>(<span class="dt">option =</span> <span class="st">"plasma"</span>)  </span></code></pre></div>
<p><img src="airt_files/figure-html/example2-1.png" width="768"></p>
<p>The figure above shows the probability density of the fitted IRT model over Theta and z values. The y axis denotes the normalized performance values. The high density regions are showed by the lighter coloured parts.</p>
</div>
<div id="classification-algorithms--latent-trait-analysis" class="section level2">
<h2 class="hasAnchor">
<a href="#classification-algorithms--latent-trait-analysis" class="anchor"></a>Classification Algorithms -Latent Trait Analysis</h2>
<p>We can also look at the datasets and their easiness with respect to the algorithms. This is called the latent trait analysis.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a></span>
<span id="cb3-2"><a href="#cb3-2"></a>obj &lt;-<span class="st"> </span><span class="kw"><a href="../reference/latent_trait_analysis.html">latent_trait_analysis</a></span>(df2,modout<span class="op">$</span>model<span class="op">$</span>param,min.item,max.item )</span>
<span id="cb3-3"><a href="#cb3-3"></a></span>
<span id="cb3-4"><a href="#cb3-4"></a>dfl &lt;-<span class="st"> </span>obj<span class="op">$</span>longdf</span>
<span id="cb3-5"><a href="#cb3-5"></a></span>
<span id="cb3-6"><a href="#cb3-6"></a>g1 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(dfl, <span class="kw">aes</span>(Latent_Trait, value)) <span class="op">+</span><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">color=</span>Algorithm)) <span class="op">+</span><span class="st"> </span><span class="kw">xlab</span>(<span class="st">"Latent Trait (Dataset Easiness)"</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">"Performance"</span>)  <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>() </span>
<span id="cb3-7"><a href="#cb3-7"></a>g1</span></code></pre></div>
<p><img src="airt_files/figure-html/latenttrait-1.png" width="768"></p>
<p>The figure above shows the performance of the 10 algorithms on different datasets ordered by dataset easiness. Or, we can split it by algorithm.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1"></a></span>
<span id="cb4-2"><a href="#cb4-2"></a>g3 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(dfl, <span class="kw">aes</span>(Latent_Trait, value)) <span class="op">+</span><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">color=</span>Algorithm)) <span class="op">+</span><span class="st"> </span><span class="kw">xlab</span>(<span class="st">"Latent Trait (Dataset Easiness)"</span>) <span class="op">+</span><span class="st"> </span><span class="kw">facet_wrap</span>(<span class="op">~</span>Algorithm, <span class="dt">nrow=</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">coord_fixed</span>(<span class="dt">ratio=</span><span class="dv">6</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">"Performance"</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>() </span>
<span id="cb4-3"><a href="#cb4-3"></a>g3</span></code></pre></div>
<p><img src="airt_files/figure-html/latent2-1.png" width="768"></p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a></span>
<span id="cb5-2"><a href="#cb5-2"></a><span class="co">### Curve fitting - smoothing splines - latent trait</span></span>
<span id="cb5-3"><a href="#cb5-3"></a>g2 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(dfl, <span class="kw">aes</span>(Latent_Trait, value)) <span class="op">+</span><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="kw">aes</span>(<span class="dt">color=</span>Algorithm), <span class="dt">se =</span> <span class="ot">FALSE</span>, <span class="dt">method =</span> <span class="st">"gam"</span>, <span class="dt">formula =</span> y <span class="op">~</span><span class="kw">s</span>(x, <span class="dt">bs=</span><span class="st">"cs"</span>))<span class="op">+</span><span class="st">  </span><span class="kw">xlab</span>(<span class="st">"Latent Trait (Dataset Easiness)"</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">"Performance"</span>)  <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()  <span class="op">+</span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">"bottom"</span>, <span class="dt">legend.box =</span> <span class="st">"horizontal"</span>)</span>
<span id="cb5-4"><a href="#cb5-4"></a>g2</span></code></pre></div>
<p><img src="airt_files/figure-html/latent3-1.png" width="768"></p>
<p>Next, we fit smoothing-splines to the performance data by algorithm. The figure above shows these smoothing splines for each algorithm as a function of the dataset easiness. From this figure, we can get the best algorithm for a given dataset easiness. This gives us the proportion of the latent trait spectrum occupied by each algorithm. We call this the latent trait occupancy.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1"></a>latent &lt;-<span class="st"> </span>obj<span class="op">$</span>latent</span>
<span id="cb6-2"><a href="#cb6-2"></a>latent<span class="op">$</span>proportions</span>
<span id="cb6-3"><a href="#cb6-3"></a><span class="co">#&gt;   group algorithm Proportion  colour</span></span>
<span id="cb6-4"><a href="#cb6-4"></a><span class="co">#&gt; 1    10   RBF_SVM     0.2250 #FF62BC</span></span>
<span id="cb6-5"><a href="#cb6-5"></a><span class="co">#&gt; 2     2       J48     0.3125 #D89000</span></span>
<span id="cb6-6"><a href="#cb6-6"></a><span class="co">#&gt; 3     3       KNN     0.0375 #A3A500</span></span>
<span id="cb6-7"><a href="#cb6-7"></a><span class="co">#&gt; 4     4     L_SVM     0.3000 #39B600</span></span>
<span id="cb6-8"><a href="#cb6-8"></a><span class="co">#&gt; 5     7  poly_SVM     0.1250 #00B0F6</span></span>
<span id="cb6-9"><a href="#cb6-9"></a></span>
<span id="cb6-10"><a href="#cb6-10"></a>setColors &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/stats/setNames.html">setNames</a></span>( latent<span class="op">$</span>proportions<span class="op">$</span>colour, latent<span class="op">$</span>proportions<span class="op">$</span>algorithm)</span>
<span id="cb6-11"><a href="#cb6-11"></a></span>
<span id="cb6-12"><a href="#cb6-12"></a>df2 &lt;-<span class="st"> </span>latent<span class="op">$</span>latent</span>
<span id="cb6-13"><a href="#cb6-13"></a>df3 &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span>(df2, <span class="dt">y=</span><span class="dv">1</span>)</span>
<span id="cb6-14"><a href="#cb6-14"></a>df3 &lt;-<span class="st"> </span>df3[ ,<span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">2</span>)]</span>
<span id="cb6-15"><a href="#cb6-15"></a>g4 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(df3, <span class="kw">aes</span>(x,y)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">color=</span>Algorithm),<span class="dt">size=</span><span class="dv">2</span>, <span class="dt">shape=</span><span class="dv">15</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">""</span>) <span class="op">+</span><span class="st"> </span><span class="kw">coord_fixed</span>(<span class="dt">ratio =</span> <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme</span>(<span class="dt">axis.title.y=</span><span class="kw">element_blank</span>(), <span class="dt">axis.text.y=</span><span class="kw">element_blank</span>(),<span class="dt">axis.ticks.y=</span><span class="kw">element_blank</span>()) <span class="op">+</span><span class="st"> </span><span class="kw">scale_color_manual</span>(<span class="dt">values =</span> setColors) <span class="op">+</span><span class="st"> </span><span class="kw">xlab</span>(<span class="st">"Latent Trait"</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">"bottom"</span>, <span class="dt">legend.box=</span><span class="st">"vertical"</span>, <span class="dt">legend.margin=</span><span class="kw">margin</span>())  <span class="op">+</span><span class="kw">guides</span>(<span class="dt">group=</span><span class="kw">guide_legend</span>(<span class="dt">nrow=</span><span class="dv">3</span>))</span>
<span id="cb6-16"><a href="#cb6-16"></a>g4</span></code></pre></div>
<p><img src="airt_files/figure-html/latent%204-1.png" width="768"></p>
<p>We see latent trait occupancy in the graph above. The 5 algorithms J48, KNN L_SVM, poly_SVM and RBF_SVM occupy parts of the latent trait spectrum. That is, for some dataset easiness values, these algorithms display superiority.</p>
</div>
<div id="classification-algorithms---polytomous-irt-model" class="section level2">
<h2 class="hasAnchor">
<a href="#classification-algorithms---polytomous-irt-model" class="anchor"></a>Classification Algorithms - Polytomous IRT model</h2>
<p>We have binned the data so that we can fit a polytomous IRT model to it. The lowest performance measurement is P1 and the highest is P5, with the others in between. The latent scores <span class="math inline">\(\theta\)</span> represent the easiness of the datasets. Let’s fit an IRT model to this data and look at the algorithm trace lines.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1"></a><span class="kw"><a href="https://rdrr.io/r/utils/data.html">data</a></span>(<span class="st">"classification_poly"</span>)</span>
<span id="cb7-2"><a href="#cb7-2"></a>modout &lt;-<span class="st"> </span><span class="kw"><a href="../reference/pirtmodel.html">pirtmodel</a></span>(classification_poly, <span class="dt">vpara=</span><span class="ot">FALSE</span>)</span>
<span id="cb7-3"><a href="#cb7-3"></a></span>
<span id="cb7-4"><a href="#cb7-4"></a>gdf &lt;-<span class="st"> </span><span class="kw"><a href="../reference/prepare_for_plots_poly.html">prepare_for_plots_poly</a></span>(modout<span class="op">$</span>model)</span>
<span id="cb7-5"><a href="#cb7-5"></a><span class="kw">ggplot</span>(gdf, <span class="kw">aes</span>(Theta, value)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">color=</span>Level)) <span class="op">+</span><span class="st"> </span><span class="kw">facet_wrap</span>(.<span class="op">~</span>Algorithm) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">"Probability"</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">"Classification Algorithm Trace Lines"</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</span></code></pre></div>
<p><img src="airt_files/figure-html/example-1.png" width="768"></p>
<p>The trace lines give the probability of getting performance levels from P1 to P5, for different values of dataset easiness denoted by theta. The probability of getting P5 is higher for an easy dataset, while it is lower for a difficult dataset. We see that some algorithms have only levels P3 to P5, while some have all performance levels. Also, some algorithms like QDA have gentler transitions between the most likely performance levels, and some like RBF_SVM have very sharp transitions.</p>
</div>
<div id="irt-model-goodness" class="section level2">
<h2 class="hasAnchor">
<a href="#irt-model-goodness" class="anchor"></a>IRT Model Goodness</h2>
<p>But how good is our IRT model? Can we trust the algorithm trace lines? To check how good the IRT model is we compute the goodness of model in this way. The IRT model has computed latent scores for all the datasets. These scores tell us how easy or hard the datasets are. A high value of theta indicates an easy dataset. For each algorithm using the latent scores and the algorithm trace lines, we can predict the performance of the IRT model for each dataset. This is not 100% correct. Then we can compare the predicted performance with the actual performance values. That is what we do here. Let’s look at the model goodness curves.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1"></a><span class="co"># Model Goodness and Algorithm effectiveness</span></span>
<span id="cb8-2"><a href="#cb8-2"></a>good &lt;-<span class="st"> </span><span class="kw"><a href="../reference/model_goodness_poly.html">model_goodness_poly</a></span>(modout<span class="op">$</span>model)</span>
<span id="cb8-3"><a href="#cb8-3"></a></span>
<span id="cb8-4"><a href="#cb8-4"></a>good_curves &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span>(good<span class="op">$</span>curves)</span>
<span id="cb8-5"><a href="#cb8-5"></a><span class="kw"><a href="https://rdrr.io/r/base/print.html">print</a></span>(good_curves)</span>
<span id="cb8-6"><a href="#cb8-6"></a><span class="co">#&gt;      x        NB       LDA       QDA      CART       J48       KNN</span></span>
<span id="cb8-7"><a href="#cb8-7"></a><span class="co">#&gt; 1 0.00 0.7446809 0.7914894 0.4468085 0.9361702 0.9361702 0.9276596</span></span>
<span id="cb8-8"><a href="#cb8-8"></a><span class="co">#&gt; 2 0.25 0.9829787 0.8893617 0.6936170 0.9957447 1.0000000 0.9957447</span></span>
<span id="cb8-9"><a href="#cb8-9"></a><span class="co">#&gt; 3 0.50 0.9914894 0.9446809 0.8723404 0.9957447 1.0000000 1.0000000</span></span>
<span id="cb8-10"><a href="#cb8-10"></a><span class="co">#&gt; 4 0.75 0.9914894 0.9659574 0.8978723 0.9957447 1.0000000 1.0000000</span></span>
<span id="cb8-11"><a href="#cb8-11"></a><span class="co">#&gt; 5 1.00 0.9957447 1.0000000 0.9957447 0.9957447 1.0000000 1.0000000</span></span>
<span id="cb8-12"><a href="#cb8-12"></a><span class="co">#&gt;       L_SVM  poly_SVM   RBF_SVM     RandF</span></span>
<span id="cb8-13"><a href="#cb8-13"></a><span class="co">#&gt; 1 0.9191489 0.8553191 0.9787234 0.7446809</span></span>
<span id="cb8-14"><a href="#cb8-14"></a><span class="co">#&gt; 2 0.9872340 0.9787234 0.9957447 0.9063830</span></span>
<span id="cb8-15"><a href="#cb8-15"></a><span class="co">#&gt; 3 0.9914894 0.9829787 0.9957447 0.9531915</span></span>
<span id="cb8-16"><a href="#cb8-16"></a><span class="co">#&gt; 4 0.9957447 0.9829787 0.9957447 0.9702128</span></span>
<span id="cb8-17"><a href="#cb8-17"></a><span class="co">#&gt; 5 0.9957447 0.9829787 0.9957447 1.0000000</span></span>
<span id="cb8-18"><a href="#cb8-18"></a>good_df &lt;-<span class="st"> </span>good_curves <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pivot_longer</span>(<span class="dt">cols=</span><span class="dv">2</span><span class="op">:</span><span class="kw"><a href="https://rdrr.io/r/base/dim.html">dim</a></span>(good_curves)[<span class="dv">2</span>], <span class="dt">names_to=</span><span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"Algorithm"</span>))</span>
<span id="cb8-19"><a href="#cb8-19"></a><span class="kw">ggplot</span>(good_df, <span class="kw">aes</span>(x,value)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">color =</span> Algorithm), <span class="dt">size=</span><span class="dv">1</span>) <span class="op">+</span><span class="st"> </span><span class="kw">xlab</span>(<span class="st">"Goodness Tolerance"</span>)  <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">"Model Goodness Curve"</span>) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</span></code></pre></div>
<p><img src="airt_files/figure-html/goodness-1.png" width="768"></p>
<p>The x axis is the goodness tolerance. That is, the values at x=0 tell you the percentage of actual = predicted for each algorithm. We see that for QDA only 45% of actual performance values equals the IRT predicted performance values, while for CART more than 95% of the actual performance values equals the IRT predicted performance values.</p>
<p>If we make the definition of goodness slightly broader and include the proportion of predicted deviating from the actual by 1, then for QDA nearly 70% of the datasets are within that margin and for CART it is this proportion is nearly 100%. In this manner we relax the tolerance. The <em>curves</em> list out these coordinates for each algorithm for each goodness tolerance level x. The area under the curve is an indication of how accurate the IRT model is on a given algorithm.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1"></a>good<span class="op">$</span>goodnessAUC</span>
<span id="cb9-2"><a href="#cb9-2"></a><span class="co">#&gt;               [,1]</span></span>
<span id="cb9-3"><a href="#cb9-3"></a><span class="co">#&gt; NB       0.9590426</span></span>
<span id="cb9-4"><a href="#cb9-4"></a><span class="co">#&gt; LDA      0.9239362</span></span>
<span id="cb9-5"><a href="#cb9-5"></a><span class="co">#&gt; QDA      0.7962766</span></span>
<span id="cb9-6"><a href="#cb9-6"></a><span class="co">#&gt; CART     0.9882979</span></span>
<span id="cb9-7"><a href="#cb9-7"></a><span class="co">#&gt; J48      0.9920213</span></span>
<span id="cb9-8"><a href="#cb9-8"></a><span class="co">#&gt; KNN      0.9898936</span></span>
<span id="cb9-9"><a href="#cb9-9"></a><span class="co">#&gt; L_SVM    0.9829787</span></span>
<span id="cb9-10"><a href="#cb9-10"></a><span class="co">#&gt; poly_SVM 0.9659574</span></span>
<span id="cb9-11"><a href="#cb9-11"></a><span class="co">#&gt; RBF_SVM  0.9936170</span></span>
<span id="cb9-12"><a href="#cb9-12"></a><span class="co">#&gt; RandF    0.9255319</span></span></code></pre></div>
<p>We see that the goodness of the IRT model is quite high for most algorithms apart from QDA. For QDA it is 0.79, which is low compared to the rest.</p>
</div>
<div id="algorithm-effectiveness" class="section level2">
<h2 class="hasAnchor">
<a href="#algorithm-effectiveness" class="anchor"></a>Algorithm Effectiveness</h2>
<p>Suppose algorithm A gives good performance values and algorithm B gives poor performance values for most of the test instances. Then, we can say that algorithm A is more effective than algorithm B. Basically, this is our notion of effectiveness. We compute the proportion of datasets that achieve the highest performance value, P5 in this example. Then we compute the proportion of datasets that achieve the levels P5 and P4. Next the proportion of datasets that obtains P5, P4 or P3. We do this computation for actual performance values and IRT model predicted performance values. These two sets of effectiveness curves are shown in the 2 graphs below.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a>eff &lt;-<span class="st"> </span><span class="kw"><a href="../reference/effectiveness_poly.html">effectiveness_poly</a></span>(modout<span class="op">$</span>model)</span>
<span id="cb10-2"><a href="#cb10-2"></a></span>
<span id="cb10-3"><a href="#cb10-3"></a>eff_curves &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span>(eff<span class="op">$</span>actcurves)</span>
<span id="cb10-4"><a href="#cb10-4"></a>eff_df1 &lt;-<span class="st"> </span>eff_curves <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pivot_longer</span>(<span class="dt">cols=</span><span class="dv">2</span><span class="op">:</span><span class="kw"><a href="https://rdrr.io/r/base/dim.html">dim</a></span>(eff_curves)[<span class="dv">2</span>], <span class="dt">names_to=</span><span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"Algorithm"</span>))</span>
<span id="cb10-5"><a href="#cb10-5"></a></span>
<span id="cb10-6"><a href="#cb10-6"></a>eff_curves &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span>(eff<span class="op">$</span>prdcurves)</span>
<span id="cb10-7"><a href="#cb10-7"></a>eff_df2 &lt;-<span class="st"> </span>eff_curves <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pivot_longer</span>(<span class="dt">cols=</span><span class="dv">2</span><span class="op">:</span><span class="kw"><a href="https://rdrr.io/r/base/dim.html">dim</a></span>(eff_curves)[<span class="dv">2</span>], <span class="dt">names_to=</span><span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"Algorithm"</span>))</span>
<span id="cb10-8"><a href="#cb10-8"></a></span>
<span id="cb10-9"><a href="#cb10-9"></a>eff_df &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/cbind.html">rbind.data.frame</a></span>(eff_df1, eff_df2)</span>
<span id="cb10-10"><a href="#cb10-10"></a>eff_df &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/cbind.html">cbind.data.frame</a></span>( eff_df, <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>( <span class="kw"><a href="https://rdrr.io/r/base/rep.html">rep</a></span>( <span class="st">"Actual Effectiveness"</span>, <span class="kw"><a href="https://rdrr.io/r/base/dim.html">dim</a></span>(eff_df1)[<span class="dv">1</span>]), <span class="kw"><a href="https://rdrr.io/r/base/rep.html">rep</a></span>(<span class="st">"Predicted Effectiveness"</span>, <span class="kw"><a href="https://rdrr.io/r/base/dim.html">dim</a></span>(eff_df2)[<span class="dv">1</span>]) ) )</span>
<span id="cb10-11"><a href="#cb10-11"></a><span class="kw"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span>(eff_df)[<span class="dv">4</span>] &lt;-<span class="st"> "Act_Or_Pred"</span></span>
<span id="cb10-12"><a href="#cb10-12"></a><span class="kw">ggplot</span>(eff_df, <span class="kw">aes</span>(x, value)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">color =</span> Algorithm), <span class="dt">size=</span><span class="dv">1</span>)  <span class="op">+</span><span class="st"> </span><span class="kw">facet_wrap</span>(<span class="op">~</span>Act_Or_Pred) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</span></code></pre></div>
<p><img src="airt_files/figure-html/effectiveness1-1.png" width="768"></p>
<p>Similar to the model goodness curves, we can find the area under the actual effectiveness curve and the predicted effectiveness curve. This will show how much the IRT predicted deviates from the actual, and also which algorithms are more effective than others. We show this in the graph below.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1"></a>df_eff &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/cbind.html">cbind.data.frame</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span>(eff<span class="op">$</span>effectivenessAUC), <span class="kw"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span>(eff<span class="op">$</span>effectivenessAUC) )</span>
<span id="cb11-2"><a href="#cb11-2"></a><span class="kw"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span>(df_eff)[<span class="dv">3</span>] &lt;-<span class="st"> "Algorithm"</span></span>
<span id="cb11-3"><a href="#cb11-3"></a></span>
<span id="cb11-4"><a href="#cb11-4"></a><span class="kw">ggplot</span>(df_eff, <span class="kw">aes</span>(Actual, Predicted)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_jitter</span>(<span class="kw">aes</span>(<span class="dt">color=</span>Algorithm), <span class="dt">size=</span><span class="dv">3</span>) <span class="op">+</span><span class="st"> </span><span class="kw">geom_abline</span>(<span class="kw">aes</span>(<span class="dt">intercept=</span><span class="dv">0</span>,<span class="dt">slope=</span><span class="dv">1</span>), <span class="dt">linetype=</span><span class="st">"dotted"</span>) <span class="op">+</span><span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/graphics/plot.window.html">xlim</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="dv">0</span>,<span class="dv">1</span>)) <span class="op">+</span><span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/graphics/plot.window.html">ylim</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="dv">0</span>,<span class="dv">1</span>)) <span class="op">+</span><span class="st"> </span><span class="kw">xlab</span>(<span class="st">"Area under Actual Effectiveness Curve (AUAEC)"</span>) <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">"Area under Predicted Effectiveness Curve (AUPEC)"</span>) <span class="op">+</span><span class="st">  </span><span class="kw">theme_bw</span>()</span></code></pre></div>
<p><img src="airt_files/figure-html/effectiveness2-1.png" width="768"></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1"></a></span>
<span id="cb12-2"><a href="#cb12-2"></a>measures &lt;-<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/cbind.html">cbind.data.frame</a></span>(good<span class="op">$</span>goodnessAUC, eff<span class="op">$</span>effectivenessAUC)</span>
<span id="cb12-3"><a href="#cb12-3"></a><span class="kw"><a href="https://rdrr.io/r/base/print.html">print</a></span>(measures)</span>
<span id="cb12-4"><a href="#cb12-4"></a><span class="co">#&gt;          good$goodnessAUC    Actual Predicted</span></span>
<span id="cb12-5"><a href="#cb12-5"></a><span class="co">#&gt; NB              0.9590426 0.9244681 0.9553191</span></span>
<span id="cb12-6"><a href="#cb12-6"></a><span class="co">#&gt; LDA             0.9239362 0.8973404 0.9420213</span></span>
<span id="cb12-7"><a href="#cb12-7"></a><span class="co">#&gt; QDA             0.7962766 0.7202128 0.8468085</span></span>
<span id="cb12-8"><a href="#cb12-8"></a><span class="co">#&gt; CART            0.9882979 0.9521277 0.9585106</span></span>
<span id="cb12-9"><a href="#cb12-9"></a><span class="co">#&gt; J48             0.9920213 0.9579787 0.9606383</span></span>
<span id="cb12-10"><a href="#cb12-10"></a><span class="co">#&gt; KNN             0.9898936 0.9563830 0.9579787</span></span>
<span id="cb12-11"><a href="#cb12-11"></a><span class="co">#&gt; L_SVM           0.9829787 0.9430851 0.9547872</span></span>
<span id="cb12-12"><a href="#cb12-12"></a><span class="co">#&gt; poly_SVM        0.9659574 0.9015957 0.9319149</span></span>
<span id="cb12-13"><a href="#cb12-13"></a><span class="co">#&gt; RBF_SVM         0.9936170 0.9494681 0.9553191</span></span>
<span id="cb12-14"><a href="#cb12-14"></a><span class="co">#&gt; RandF           0.9255319 0.9148936 0.9702128</span></span></code></pre></div>
<p>The table above shows the area under the model goodness curve and the areas under the actual and predicted effectiveness curves.</p>
</div>
<div id="two-more-measures" class="section level2">
<h2 class="hasAnchor">
<a href="#two-more-measures" class="anchor"></a>Two more measures</h2>
<p>We define two more measures for algorithms: stability and anomalous nature. Algoroithms are stable if the transitions between the most likely performance levels are smoother. This can be seen from the algorithm trace lines. For example QDA and LDA have smoother transitions compared to RBF_SVM. This is related to the discrimination parameter in an IRT. We define stability as K - |discrimination|, where K is the highest absolute discrimination value.</p>
<p>In addition, some algorithms are anomalous. That is they perform well on datasets where the other algorithms perform poorly. We say an algorithm is anomalous is the IRT discrimination parameter is negative. In this example non of the algorithms are anomalous.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1"></a>stab &lt;-<span class="st"> </span>modout<span class="op">$</span>stability</span>
<span id="cb13-2"><a href="#cb13-2"></a>anomalous &lt;-<span class="st"> </span>modout<span class="op">$</span>anomalous</span>
<span id="cb13-3"><a href="#cb13-3"></a><span class="kw"><a href="https://rdrr.io/r/base/cbind.html">cbind.data.frame</a></span>(stab, anomalous)</span>
<span id="cb13-4"><a href="#cb13-4"></a><span class="co">#&gt;                stab anomalous</span></span>
<span id="cb13-5"><a href="#cb13-5"></a><span class="co">#&gt; NB       0.52833936         0</span></span>
<span id="cb13-6"><a href="#cb13-6"></a><span class="co">#&gt; LDA      0.92182505         0</span></span>
<span id="cb13-7"><a href="#cb13-7"></a><span class="co">#&gt; QDA      2.85482903         0</span></span>
<span id="cb13-8"><a href="#cb13-8"></a><span class="co">#&gt; CART     0.15932110         0</span></span>
<span id="cb13-9"><a href="#cb13-9"></a><span class="co">#&gt; J48      0.15898528         0</span></span>
<span id="cb13-10"><a href="#cb13-10"></a><span class="co">#&gt; KNN      0.14889309         0</span></span>
<span id="cb13-11"><a href="#cb13-11"></a><span class="co">#&gt; L_SVM    0.16084800         0</span></span>
<span id="cb13-12"><a href="#cb13-12"></a><span class="co">#&gt; poly_SVM 0.28802969         0</span></span>
<span id="cb13-13"><a href="#cb13-13"></a><span class="co">#&gt; RBF_SVM  0.07019147         0</span></span>
<span id="cb13-14"><a href="#cb13-14"></a><span class="co">#&gt; RandF    0.84867217         0</span></span></code></pre></div>
<p>More examples of algorithm evaluation using airt are discussed in our paper <span class="citation">(Kandanaarachchi and Smith-Miles 2020)</span>.</p>
</div>
<div id="references" class="section level2 unnumbered">
<h2 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h2>
<div id="refs" class="references hanging-indent">
<div id="ref-airtPaper">
<p>Kandanaarachchi, Sevvandi, and Kate Smith-Miles. 2020. “Enriching Algorithm Portfolio Evaluation Using Item Response Theory.” <em>Working Paper</em>. RMIT University. <a href="https://bit.ly/algorithmirt">https://bit.ly/algorithmirt</a>.</p>
</div>
<div id="ref-munoz2018instance">
<p>Muñoz, Mario A, Laura Villanova, Davaatseren Baatar, and Kate Smith-Miles. 2018. “Instance Spaces for Machine Learning Classification.” <em>Machine Learning</em> 107 (1): 109–47.</p>
</div>
<div id="ref-matilda">
<p>Smith-Miles, Kate. 2019. <em>MATILDA: Melbourne Algorithm Test Instance Library with Data Analytics</em>. <a href="https://matilda.unimelb.edu.au/">https://matilda.unimelb.edu.au/</a>.</p>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">

        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#classification-algorithms---continuous-irt-model">Classification Algorithms - Continuous IRT model</a></li>
      <li><a href="#classification-algorithms--latent-trait-analysis">Classification Algorithms -Latent Trait Analysis</a></li>
      <li><a href="#classification-algorithms---polytomous-irt-model">Classification Algorithms - Polytomous IRT model</a></li>
      <li><a href="#irt-model-goodness">IRT Model Goodness</a></li>
      <li><a href="#algorithm-effectiveness">Algorithm Effectiveness</a></li>
      <li><a href="#two-more-measures">Two more measures</a></li>
      <li><a href="#references">References</a></li>
      </ul>
</div>
      </div>

</div>



      <footer><div class="copyright">
  <p>Developed by Sevvandi Kandanaarachchi.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.4.0.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
